--------------------------- Tutorial Control ------------------------- 

---> El proceso se ha realizado con ROS Noetic, aunque no debería dar problema para otras distribuciones

  - 1. Clonar el repositorio Github con los paquetes del Kinova en el direcotrio "my_project/src". Este paquete está en el directorio
"kinova" de nuestro repositorio:
        git clone https://github.com/Kinovarobotics/kinova-ros
       
       Instalar ROS-Control:
        sudo apt-get install ros-$distro-ros-control ros-$distro-ros-controllers
       
       Instalar Robotic-Toolbox Python:
        pip install roboticstoolbox-python 
       
       Instalar MoveIT:
        sudo apt install ros-noetic-moveit-core
        sudo apt install ros-noetic-moveit-ros-move-group
        sudo apt install ros-noetic-moveit 
       
  - 2. Desde "my_project" compilar y actualizar el bash:
  	rm build 
	rm devel
        catkin_make & source devel/setup.bash
	for conda users get into ur env and:
	catkin_make -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.7m

  - IMPORTANTE: el paquete incorpora varios modelos de robots de la marca Kinova (Mico, Jaco, ...) por lo que cada programa está preparado
para recibir cualquiera. Así, hay varias condiciones "if" según el nombre del robot. En nuestro caso estaremos usando el j2n6s300, que quiere
decir un robot Kinova Jaco versión 2.0 con 3 dedos en el efector final y seis grados de libertad. 

  - 3. Paquetes relevantes en la simulación:
        3.1. GAZEBO: "kinova_roscontrol/src/kinova-ros/kinova_gazebo": Los paquetes de simulación están en esta carpeta . Ahí hay dos sub-carpetas, "world" y "launch"
            3.1.1. World: ahí están los modelos del mundo en la simulación de Gazebo. En nuestro caso estamos usando un archivo personalizado para
          simular el funcionamiento del robot, el "arm_example.world". Ahí se importan elementos básicos como el suelo o una luz, un armario pero está
          comentado, se indica con la etiqueta "<model>bookshelf</model>". Luego, se incorporan unos objetos para simular los botes manipulables
            3.1.2. Launch: ahí están los archivos ".launch" que lanzan los programas. El "robot_launch.launch" se encarga de lanzar
          el modelo del robot, el modelo del mundo y los conroladores. 

            IMPORTANTE: si se ha instalado el repositiorio desde la web original y no desde el Github del proyecto, es importante que a la hora
          de lanzar los modelos del robot (línea 36 para nuestro robot y 48, 63 y 76 para los demás) de debe eliminar la etiqueta de "ns". Esto lo
          que provoca es que el robot lance sus topics con un espacio de nombres determinado, lo que provoca que el ROS-Control y Gazebo no detecten
          las articulaciones, pues no tienen el nombre esperado, por lo que no se consigue cargar el controlador. 
            Otra opción sería cambiar el controlador para que pudiera aceptar ese espacio de nombres, pero en este caso se ha procedido de esta manera

        3.2. MODELOS: "kinova_roscontrol/src/kinova_description": aquí están los diferentes modelos robots Kinova.
            3.2.1: Launch: un fichero .launch que se encarga de lanzar el robot en un entorno
            3.2.2: Meshes: aquí se encuentran los modelados 3D de cada una de las articulaciones de los robots incorporados en el proyecto
            3.2.3: URDF: en esta carpeta están los archivos de configuración URDF. Estos archivos hacen referencia a los modelados tridimensionales
          de la anterior carpeta. En estos archivos no solo se importan los modelados sino que se definen inercias, masas y transimisiones, así como
          colisiones y diferentes uniones entre las piezas. El fichero que nos interesa es el "j2n6s300_standalone.xacro", que es el que se llama desde 
          el "robot_launch.launch" para importar el modelo del robot en Gazebo

        3.3. CONTROL: "kinova_roscontrol/src/kinova_control": en esta carpeta están los archivos referentes al control del robot.
            3.3.1: Config: en esta carpeta están los controladores especificados en ROS-Control. En nuestro caso, se ha creado uno personalizado, 
          más sencillo que los del ejemplo llamado "controlador.yaml". Es importante que se especiquen los nombres de la articulacuón asociada a cada
          controlador. Igualmente, el nombre que se le da al controlador es el correspondiente al topic donde se envían los comandos de movimiento.
            3.3.2: Launch: en esta carpeta están los ficheros .launch que se encargan de cargar los controladores del robot. Hay un archivo que carga
          rqt, pero no se va a usar en el proyecto
            3.3.3: Src: en esta carpeta hay un programa para mover el robot, pero da problemas para ejecutarlo y el formato no parece ser correcto

  - 4. SIMULACIÓN: para lanzar la simulación se debe ejecutar el comando:
	source devel/setup.bash
	[conda activate env_name] //if python installed in env
	roscore 
	ctr+shift+T
	source... [conda...]
	roslaunch kinova_moveit demo_gazebo.launch 
	* roslaunch controllers scullion_tiles.launch
	*rosrun controllers controller_.py
	ctr+shift+T
	source...[conda...]
	cd UI
	python controller.py
	[inputs are rgb]
	
  OTRAS FORMAS DE EJECUTAR:

  - Control mediantes las teclas del teclado, la tecla 'r', 'g' y 'b' para que el robot vaya a por los bloques rojo, verde y azul respectivamente
      roslaunch kinova_gazebo key_control.launch
      rosrun controllers controller_.py
  
  - Control mediante la voz:
      roslaunch kinova_gazebo voice_control.launch
      rosrun controllers controller_voice.py



  - 5. CONTROL EN EJECUCIÓN: la ejecución se realiza mediante ROS-Control, por lo que el control se realizará mediante topics. Para ello, se 
programará en un script de Python llamado "controller.py", ubicado en la raíz del proyecto. Cabe destacar que ROS-Control no admite de base un
controlador cartesian ORIENTATIONo, solo se admiten comandos articulares, por lo que se va a utilizar la Robotic-Toolbox de Python por Peter Corke para el cálculo
de inversas.

    LO QUE SE VA A INTENTAR HACER ES USAR EL PLANIFICADOR DE TRAYECTORIAS DE MOVEIT PERO PUBLICANDO LOS DATOS EN LOS TOPICS DE UN CONTROLADOR DE
POSICIÓN NORMAL.
    
    Se ha observado que MoveIT planifica en cartesian ORIENTATIONas, pero a la hora de pasárselo al robot se pasan a articulares. El inconveniente es que el 
topic que recibe los comandos (/$(name_group)_controller/command) solo acepta comandos tipo trajectory_msgs/JointTrajectory por lo que hace la ejecución
de la trayectoria sin supervisión
    Una alternativa podría ser la de separar los puntos y hacer la trayectoria punto por punto, aunque no seguiría el propósito del controlador y 
sería muy costoso computacionalmente separar cada punto y asignarlo a otro mensaje.
    Por lo tanto, se va a PROBAR a usar el planificador en cartesian ORIENTATIONas, computarlas para pasarlas a articulares (MoveIT) y usar un controlador 
articular para mover el robot (ROS-Control) publicando en los topics del controlador correspondientes. 

    VENTAJAS MOVEIT:                                                    VENTAJAS ROS-CONTROL + ROBOTIC TOOLBX:
      - Fácil de usar y planificar trayectorias                           - Control de trayectorias articulares
      - Capacidad de modelar cualquier robot en URDF                      - Uso de mayor variedad de controladores (posición, velocidad, par, ...)
                     
    DESVENTAJAS MOVEIT:                                                 DESVENTAJAS ROS-CONTROL + ROBOTIC TOOLBX:
      - Solo permite ejecución de trayectorias enteras                    - No permite trayectrias cartesian ORIENTATIONas directamente
    (aunque se podría modificar para hacerlo punto por punto -->          - Cálculo de inversas y posiciones ineficiente (ikine_LM)
    mucho trabajo)
      - NO permite el control de trayectorias articular
      - No permite detener la ejecución

    Al juntar estas dos herramientas se tiene un control articular con la planificación de trayectorias

    Primero se va a hacer el control con MoveIT para definir mejor las posiciones finales, luego se cogerán esas posiciones para el control de
posición directo.
    El problema que se tuvo al calcular la cinemática inversa con la Robotic-Toolbox de Peter Corke de Python era que la posicición de la que se
partía (el brazo complemente estirado) era una singularidad, por lo que al posicionarlo en otra con mayor manipulabilidad de las articulaciones
se conseguía planificar y realizar el 100% de la trayectoria programada 

    Solo con MoveIT funciona bien
    Se ha hecho un programa que reaccione a la pulsación de las teclas del teclado

    La interfaz y la cámar se va a lanzar desde un nodo a parte, de manera que reciban datos desde alli y no se coman la ejecucion del controlador
    Se ha depurado el código para que esté mas reutilizado: 
      - Solo hay una funcion de move (va al objeto) con parametros de posicionarlo
      - Solo hay un grab (para hacer cada viaje)
      - El place_on_target esta parametrizado con la posicion del lugar (por si hay varios)
      - Se añaden los atributos de cada bloque a la clase
      - Se añade una lista de los ingredientes y si estan en sus posiciones
      - Se añade una lista de comandos
    También se han añadido algunas tareas

    Se ha hecho otro controlador llamado controller_voice.py. El anterior funciona con las teclas del teclado, el nuevo se suscribe a varios topics
  como el de la interfaz por voz y la cámara. En este nuevo controlador se almacenan los comandos provenientes de la interfaz, a la vez que se 
  modifican las variables de ingredientes. El programa se ejecuta en un bucle de control implementado como un método de la clase


    Para que el control con el teclado funcione mejor se ha creado otro archivo, el controller_.py que se suscribe al topic "/teclas" publicado por otro
  nodo, el que se lanza desde el archivo teclas.py, ambos ubicados en la carpeta UI. De esta manera, desde el nodo "teclas" se detectan las pulsaciones
  de teclas y se publica en el topic. En el controlador del robot se lee ese topic y se añade su contenido a una lista de comandos. 
    La ejecución del nuevo controlador se basa en un bucle infinito y dos callbacks; uno para detectar las teclas (simulando el control por voz) y 
  otro para visualizar la cámara. Estos callbacks añaden comandos a la lista de comandos para ser ejecutados en el bucle de control
    Se ha probado con el script de la cámara y una modificación del script original del reconocimiento de arucos y se ha comprobado que funciona
  bien el algoritmo con las teclas. 
    La cámara ahora apunto directamente hacia abajo y no tiene colisión. Cuando detecta un bloque durante 10 segundos envía un callback al script de
  control, de manera que se almacena el comando en la lista de comandos.

  POSIBLES MEJORAS:
    - Feedback sonoro al usuario: que te diga que hacer
    - Control de trayectorias e interrupciones en la ejecucion: que se detecten manos (p. ej) y detenga la trayectoria
    - Añadir más ingredientes: añadir ingredientes al sistema
    - Añadir lugares de recogida: ampliar los lugares de recogida del robot. Adaptar el algoritmo de la cámara para que acepte más ingredientes que
    recoger
    - Añadir aviso de si el objeto sigue estando para su recogida, por si se ha quitado por algún motivo (con un cliente servidor o similar)

################ Cámara #######################
    Se ha añadido una camara; en el archivo de urdf del robot se incluye la siguiente línea en los includes del principio:
      - <xacro:include filename="$(find kinova_description)/urdf/camera/camera.urdf.xacro"/>

    Luego, en la macro del xacro se define la posición de la cámara (los valores puede ir cambiando):
      - <xacro:camera_v0 parent="${prefix}_link_base">
	       <origin xyz="0.4 0.4 0.5" rpy="0 0.785375 -1.57075"/>
        </xacro:camera_v0>
    
    Al final del acrhivo, justo antes de la última etiqueta, se añade:
      - <xacro:camera_gazebo_v0 />


  Se han cambiado la posición de los bloques para que hayan dos zonas; una donde el robot deja los bloques y otra desde donde los recoge, para que
no se molesten los bloques ya dejados con los que vienen. También se ha cambiado la clausura de la pinza, ahora se cierra menos para que los dedos
no tiemblen tanto al coger los objetos, los coja mal o que de un error en la planificiación de trayectorias porque la articulación no está en la
posición esperada.

  Para mejorar la actuación del robot se ha disminuido el margen de tolerancia de las posiciones objetivo, para que llegue mejor a las posiciones
y no falle tanto en las planificaciones posteriores


#####################################################################
Relación DH: (hacer esto si las posiciones no corresponden)
    Real   -->    DH
    q1      =     -q1 + 180
    q2      =     q2 + 270
    q3      =     -q3 + 90
    q4      =     -q4 + 90
    q5      =     -q5 + 180
    q6      =     -q6 + 260


Posición de inicio: 
    <joint name="j2n6s300_joint_1" value="0"/>
    <joint name="j2n6s300_joint_2" value="3.5135"/>
    <joint name="j2n6s300_joint_3" value="4.7716"/>
    <joint name="j2n6s300_joint_4" value="0.8852"/>
    <joint name="j2n6s300_joint_5" value="-2.3084"/>
    <joint name="j2n6s300_joint_6" value="1.1282"/>


Posición de agarre (superior)  (JOINTS):    (Position: [x = 0.5, y = 0.0, z = 0.26])

    <joint name="j2n6s300_joint_1" value="0.1048575812317214"/>
    <joint name="j2n6s300_joint_2" value="2.5416042919908124"/>
    <joint name="j2n6s300_joint_3" value="4.5650001372527305"/>
    <joint name="j2n6s300_joint_4" value="0.38050183567458795"/>
    <joint name="j2n6s300_joint_5" value="-1.2330303362193176"/>
    <joint name="j2n6s300_joint_6" value="0.702691615105369"/> 

                                (CARTESIAN ORIENTATION): [X = 0.794731, Y = -0.6059, Z = 0.03549, W = 0.00087]



Posición de agarre (inferior)  (JOINTS):    (Position: [x = 0.5, y = 0.0, z = 0.06])

    <joint name="j2n6s300_joint_1" value="0.10755548301292706/>
    <joint name="j2n6s300_joint_2" value="2.188503829630644"/>
    <joint name="j2n6s300_joint_3" value="4.729273331377606"/>
    <joint name="j2n6s300_joint_4" value="0.24368134950591092"/>
    <joint name="j2n6s300_joint_5" value="-0.6329153886244301"/>
    <joint name="j2n6s300_joint_6" value="0.4743015064614271"/> 

                                (CARTESIAN ORIENTATION): [X = 0.794731, Y = -0.6059, Z = 0.03549, W = 0.00087]
